<!--
 * @Author: feng 1804831168@qq.com
 * @Date: 2025-02-23 13:15:06
 * @LastEditors: feng 1804831168@qq.com
 * @LastEditTime: 2025-02-23 13:15:20
 * @Description:
 * Copyright (c) 2025 by Feng, All Rights Reserved.
-->

### 原版损失函数

```python

class RateDistortionLoss(nn.Module):
    """Custom rate distortion loss with a Lagrangian parameter."""

    def __init__(self, lmbda=1e-2):
        super().__init__()
        self.customloss = CustomLoss()
        self.lmbda      = lmbda

    def forward(self, output, target,epoch):
        N, _, H, W = target.size()
        out = {}
        num_pixels = N * H * W

        out["mse_loss"] = self.customloss(output["x_hat"], target,epoch)
        out["msssim_loss"] = 1 - ms_ssim(target, output["x_hat"], data_range=1.0)
        out["bpp_loss"] = sum(
                (torch.log(likelihoods).sum() / (-math.log(2) * num_pixels))
                for likelihoods in output["likelihoods"].values()
            )

        if args.lossMode == "ms_ssim":
            out["loss"] = self.lmbda * out["msssim_loss"] + out["bpp_loss"]
        else:
            out["loss"] = self.lmbda *255**2*out["mse_loss"] + out["bpp_loss"]
        return out
```

### 修改后损失函数

```python
class RateDistortionLoss(nn.Module):
    def __init__(self, lmbda=0.1, warmup=50, data_range=255.0):
        super().__init__()
        self.lmbda = lmbda
        self.warmup = warmup
        self.data_range = data_range

        # 改进的EMA初始化
        self.register_buffer('distortion_ema', torch.tensor(1.0))
        self.register_buffer('bpp_ema', torch.tensor(0.3))
        self.gamma = 0.9
        self.eps = 1e-8  # 统一数值安全阈值

    def forward(self, output, target, epoch):
        # 输入处理（保持原始结构）
        x_hat = output["x_hat"].clamp(0.0, 1.0)
        target_norm = target / self.data_range

        # 失真计算修正（关键错误修复）
        mse_loss = F.mse_loss(x_hat, target_norm) * (self.data_range ** 2)
        ssim_loss = 1 - ms_ssim(target_norm, x_hat, data_range=1.0)

        # 修正原始代码中的错误：0.5*mse_loss + 0.5*ssim_loss
        if epoch < self.warmup:
            distortion = mse_loss
        else:
            # 渐进式混合权重（改进稳定性）
            alpha = torch.sigmoid(torch.tensor((epoch - self.warmup) / 10.0)).item()
            distortion = (1 - alpha) * mse_loss + alpha * ssim_loss

        # 分层BPP计算（改进数值稳定性）
        bpp_loss = 0.0
        for name, l in output["likelihoods"].items():
            # 分层处理（通道维度独立）
            p = l.clamp(min=self.eps, max=1 - self.eps)
            layer_bpp = torch.log(p + self.eps).sum(dim=(1, 2, 3))  # 按通道聚合
            bpp_loss += layer_bpp.mean() / (-math.log(2) * x_hat.size(-2) * x_hat.size(-1))  # 空间维度归一化

        # 动态EMA初始化（关键改进）
        if epoch == 0:
            self.distortion_ema.copy_(distortion.detach())
            self.bpp_ema.copy_(bpp_loss.detach())
        else:
            # 自适应EMA动量（改进平衡）
            effective_gamma = min(self.gamma, epoch / (self.warmup + 1))
            self.distortion_ema = effective_gamma * self.distortion_ema + (1 - effective_gamma) * distortion.detach()
            self.bpp_ema = effective_gamma * self.bpp_ema + (1 - effective_gamma) * bpp_loss.detach()

        # 安全缩放因子计算
        ratio = (self.bpp_ema / self.distortion_ema.clamp(min=1e-4)).clamp(0.1, 10.0)
        scale = torch.sqrt(ratio.detach())

        total_loss = self.lmbda * scale * distortion + bpp_loss

        return {
            "loss": total_loss,
            "mse_loss": mse_loss,
            "msssim_loss": ssim_loss,
            "bpp_loss": bpp_loss,
            "grad_scale": scale
        }
```
