
## ImageFolder函数读取数据

**ImageFolder(root, transform=None, target_transform=None, loader=default_loader)**
**参数解释：** 
1）root：     图片存储根目录；  
2）transform：对Image进行的转换操作，原始图片作为输入，返回一个转换后的图片；  
3）target_transform：对图片类别进行预处理的操作，输入为target，输出对其的转换。如果不传该参数，即对target不做任何转换，返回的顺序索引 0,1, 2…；
4）loader：表示数据集加载方式，通常默认加载方式即可；  
**返回值：**  
self.classes：     用一个 list保存类别名称；  
self.class_to_idx：类别对应的索引，与不做任何转换返回的 target 对应；  
self.imgs：保存(img-path, class) tuple的 list；  

### imagefolder方法返回一个dataset类对象实例
**要注意返回的是一个dataset类实例对象**  
```python
 data_transform = {
        "train": transforms.Compose([transforms.RandomResizedCrop(224),
                                     transforms.RandomHorizontalFlip(),
                                     transforms.ToTensor()
                                     ]),
        "val": transforms.Compose([transforms.Resize((224, 224)),  # cannot 224, must (224, 224)
                                   transforms.ToTensor()
                                   ])}

    train_dataset = datasets.ImageFolder(root=os.path.join(data_root, "train"),
                                         transform=data_transform["train"])

    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)
    for i, (input, label) in enumerate(train_loader):
     # 进行训练操作
        pass
```

## 保存&读取模型(torch.save&torch.load)

保存整个模型：  **torch.save(model,'save.pt')**  
只保存训练好的权重： **torch.save(model.state_dict(), 'save.pt')**
torch.load(f, map_location=None, pickle_module=<module 'pickle' from '...'>)
**参数：**
f：类文件对象（返回文件描述符）或一个保存文件名的字符串
map_location：一个函数或字典规定如何映射存储设备
pickle_module：用于unpickling元数据和对象的模块（必须匹配序列化文件时的pickle_module）

```python
#加载模型
torch.load('tensors.pt')
 
# 加载模型到CPU上 Load all tensors onto the CPU
torch.load('tensors.pt', map_location=torch.device('cpu'))
 
#  加载模型到CPU上 Load all tensors onto the CPU, using a function
torch.load('tensors.pt', map_location=lambda storage, loc: storage)
 
# 加载模型到第1个GPU上 Load all tensors onto GPU 1
torch.load('tensors.pt', map_location=lambda storage, loc: storage.cuda(1))
 
# 将模型从GPU1映射到GPU0上 Map tensors from GPU 1 to GPU 0
torch.load('tensors.pt', map_location={'cuda:1':'cuda:0'})
```

**model.state_dict()函数和optimizer.state_dict()函数**
state_dict其实是pytorch中模型的可学习参数（如weight和bias）python字典，**模型的参数可通过model.parameters()获取**
只有包含了可学参数层（卷积层、池化层）和已注册的命令（registered buffers，比如batchnorm的running_mean）才会进入state_dict中，
优化目标torch.optim也有state_dict，其中包含的是优化器状态信息和使用到的超参数。
**model.state_dict()会返回一个模型参数字典。**  
model.load_state_dict：使用状态字典state_dict反序列化模型参数字典，用来加载模型参数。  
将state_dict中的parameters和buffers复制到model及其子节点中。  


### 保存阶段性模型训练过程
**Example:**
```python
torch.save({
            'modelA_state_dict': modelA.state_dict(),
            'modelB_state_dict': modelB.state_dict(),
            'optimizerA_state_dict': optimizerA.state_dict(),
            'optimizerB_state_dict': optimizerB.state_dict(),
            }, PATH)

modelA     = TheModelAClass(*args, **kwargs)
modelB     = TheModelBClass(*args, **kwargs)
optimizerA = TheOptimizerAClass(*args, **kwargs)
optimizerB = TheOptimizerBClass(*args, **kwargs)
 
checkpoint = torch.load(PATH)
modelA.load_state_dict(checkpoint['modelA_state_dict'])
modelB.load_state_dict(checkpoint['modelB_state_dict'])
optimizerA.load_state_dict(checkpoint['optimizerA_state_dict'])
optimizerB.load_state_dict(checkpoint['optimizerB_state_dict'])
 
modelA.eval()  
modelB.eval()
# - 或者 -
modelA.train()
modelB.train()

```
模型参数加载好后，要使用model.eval()来固定dropout和归一化层，否则每次预测结果会不同。  
**load_state_dict()** 需要传入字典对象，因此需要先反序列化state_dict再传入load_state_dict()。  

### GPU上保存，CPU上加载
当在CPU上加载一个GPU上训练的模型时，在torch.load()中指定map_location=torch.device(‘cpu’)， 
map_location动态地将tensors的底层存储重新映射到CPU设备上。
```python
#保存
torch.save(model.state_dict(), PATH)
#加载
device = torch.device('cpu')
model = TheModelClass(*args, **kwargs)
model.load_state_dict(torch.load(PATH, map_location=device))

上述代码只有在模型是在一块GPU上训练时才有效，如果模型在多个GPU上训练，那么在CPU上加载时，会得到类似如下错误：
KeyError: ‘unexpected key “module.conv1.weight” in state_dict’
原因是在使用多GPU训练并保存模型时，模型的参数名都带上了module前缀，因此可以在加载模型时，把key中的这个前缀去掉：

# 原始通过DataParallel保存的文件
state_dict = torch.load('myfile.pth.tar')
# 创建一个不包含`module.`的新OrderedDict
from collections import OrderedDict
new_state_dict = OrderedDict()
for k, v in state_dict.items():
    name = k[7:] # 去掉 `module.`
    new_state_dict[name] = v
# 加载参数
model.load_state_dict(new_state_dict)

```